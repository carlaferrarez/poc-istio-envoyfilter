# Controle de throttling utilizando o Istio

## ğŸš€ ComeÃ§ando

A experimentaÃ§Ã£o foi feita utilizando o sistema operacional Linux. O objetivo Ã© utilizar o EnvoyFilter (sidecar proxy) do Istio para habilitar a feature de limitaÃ§Ã£o de trÃ¡fego. O Envoy suporta 2 tipos de limitaÃ§Ã£o: local e global. As limitaÃ§Ãµes locais sÃ£o usadas para limitar as requisiÃ§Ãµes por serviÃ§o (in-mesh traffic). JÃ¡ a limitaÃ§Ã£o global Ã© utilizada para limitaÃ§Ã£o pelo ingress gateway. Nessa POC serÃ¡ utilizada apenas a global, mas as duas poderiam ser utilizadas juntas. 

<img src="images/nativexmesh.png" width=60% height=60%>

#### Vantagens do service mesh
* RemoÃ§Ã£o do controle de trÃ¡fego da camada de serviÃ§o no Kubernetes por meio do sidecar proxy - permitindo mais elasticidade.
* Controle de politicas, observability e muito mais

[ReferÃªncia](https://www.tetrate.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/)


### ğŸ“‹ PrÃ©-requisitos

* Cluster com Kubernetes rodando na mÃ¡quina. Nesse tutorial foi utilizado a versÃ£o 1.22 do Kubernetes com o minikube. [Tutorial Minikube](https://minikube.sigs.k8s.io/docs/start/)
```
minikube start 
```
<img src="images/minikube.png" width=60% height=60%>

* InstalaÃ§Ã£o do Istio. Nesse tutorial foi utilizado a versÃ£o 1.11.4 [Tutorial Istio](https://istio.io/latest/docs/setup/getting-started/)
```
istioctl version
```
<img src="images/istio.png" width=60% height=60%>

* Deploy da aplicaÃ§Ã£o padrÃ£o Bookinfo [Tutorial App](https://istio.io/latest/docs/examples/bookinfo/)
```
kubectl get pods
```
<img src="images/sample-app.png" width=60% height=60%>
<img src="images/book-info.png" width=60% height=60%>


### ğŸ”§ Desenvolvimento

<img src="https://user-images.githubusercontent.com/36728177/145292617-e713cbdd-10ef-4022-8c9f-19a7722dba03.png" width=60% height=60%>

O serviÃ§o rate limit Ã© um serviÃ§o Go / gRPC projetado para permitir cenÃ¡rios genÃ©ricos de limite de taxa de diferentes tipos de aplicativos. Os aplicativos solicitam uma decisÃ£o de limite de taxa com base em um domÃ­nio e um conjunto de descritores. O serviÃ§o lÃª a configuraÃ§Ã£o do disco por meio do tempo de execuÃ§Ã£o, compÃµe uma chave de cache e se comunica com o cache do Redis. A decisÃ£o Ã© entÃ£o devolvida ao chamador.

[ReferÃªncia](https://github.com/envoyproxy/ratelimit#configuration)

Executando os scripts para criaÃ§Ã£o da infraestrutura:

```
kubectl apply -f config/config-map.yaml
```

No nosso caso poderia ser um arquivo editado pelos nossos consumidores.

```
kubectl apply -f config/rate-limit-svc.yaml
```

```
kubectl apply -f config/envoy-filter.yaml
```

##### ObservaÃ§Ã£o: ao alterar o ConfigMap, o serviÃ§o do ratelimit deve ser reiniciado. Ã‰ uma limitaÃ§Ã£o da feature. Existe uma soluÃ§Ã£o paralela que pode ser utilizada, mas ainda nÃ£o foi testada

```
https://kubectl.docs.kubernetes.io/guides/config_management/secrets_configmaps/
```


## âš™ï¸ Executando os testes

Explicar como executar os testes automatizados para este sistema.

### ğŸ”© Analise testes de carga

#### Teste sem o header api-key

<img src="images/5rps-noheader.png" width=80% height=80%>

#### Teste com o header api-key sem parÃ¢metro limitador

<img src="images/5rps.png" width=80% height=80%>

#### Teste com o header api-key com parÃ¢metro limitador

<img src="images/2rps.png" width=80% height=80%>

## ğŸ“Œ Limpando o ambiente 

Explicar como executar os testes automatizados para este sistema.

```
kubectl delete deployment ratelimit
kubectl delete deployment redis
kubectl delete envoyfilter filter-ratelimit -n istio-system
kubectl delete envoyfilter filter-ratelimit-svc -n istio-system
kubectl delete svc redis
kubectl delete svc ratelimit
```

## âœ’ï¸ PrÃ³ximos passos

Refinar a aplicabilidade de usar o local rate limit.

---
âŒ¨ï¸ com â¤ï¸ por [Armstrong LohÃ£ns](https://gist.github.com/lohhans) ğŸ˜Š
